{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "**Objective**: Sun Pharma needs to test 80,000 new painkiller drugs for two key parameters:\n",
    "1. **Time of Effect**: The duration it takes for the drug to completely cure the pain.\n",
    "2. **Quality Assurance**: Whether the drug performs satisfactorily in curing the pain.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Steps to Address the Problem\n",
    "\n",
    "#### 1. Data Collection\n",
    "- **Parameters to Measure**:\n",
    "  - Time of Effect: This is a continuous variable measured in minutes/hours.\n",
    "  - Quality Assurance: This is a binary variable (Satisfactory/Not Satisfactory).\n",
    "- **Sample Size**: 80,000 drugs need to be tested.\n",
    "\n",
    "#### 2. Exploratory Data Analysis (EDA)\n",
    "- **Descriptive Statistics**:\n",
    "  - Summary statistics (mean, median, mode, standard deviation, etc.) for the Time of Effect.\n",
    "  - Distribution of Quality Assurance results.\n",
    "- **Visualizations**:\n",
    "  - Histograms/Box plots for Time of Effect.\n",
    "  - Bar charts/Pie charts for Quality Assurance results.\n",
    "  - Scatter plots to identify any potential relationships between Time of Effect and Quality Assurance.\n",
    "\n",
    "#### 3. Data Preprocessing\n",
    "- **Handling Missing Values**: Identify and handle missing or inconsistent data.\n",
    "- **Data Transformation**: Normalize/standardize the Time of Effect if needed.\n",
    "- **Encoding Categorical Data**: Convert the Quality Assurance results into numerical values (e.g., 0 for Not Satisfactory, 1 for Satisfactory).\n",
    "\n",
    "#### 4. Statistical Analysis\n",
    "- **Hypothesis Testing**:\n",
    "  - Test whether the mean Time of Effect meets a specified standard.\n",
    "  - Compare the proportions of satisfactory results across different batches if applicable.\n",
    "- **Confidence Intervals**:\n",
    "  - Calculate confidence intervals for the mean Time of Effect.\n",
    "  - Calculate confidence intervals for the proportion of satisfactory Quality Assurance results.\n",
    "\n",
    "#### 5. Predictive Modeling\n",
    "- **Regression Analysis**:\n",
    "  - Use linear regression to predict the Time of Effect based on various features.\n",
    "- **Classification Models**:\n",
    "  - Use logistic regression, decision trees, or other classification algorithms to predict Quality Assurance results.\n",
    "  - Evaluate model performance using metrics like accuracy, precision, recall, and F1-score.\n",
    "\n",
    "#### 6. Reporting and Insights\n",
    "- **Summary Report**:\n",
    "  - Summarize key findings from EDA, statistical analysis, and predictive modeling.\n",
    "  - Provide actionable insights and recommendations.\n",
    "- **Visualizations**:\n",
    "  - Create visualizations to communicate the results effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code Snippets\n",
    "\n",
    "#### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('painkiller_test_data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "data['quality_assurance'] = data['quality_assurance'].map({'Satisfactory': 1, 'Not Satisfactory': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Descriptive statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Histograms\n",
    "sns.histplot(data['time_of_effect'], kde=True)\n",
    "plt.title('Distribution of Time of Effect')\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for Quality Assurance\n",
    "sns.countplot(x='quality_assurance', data=data)\n",
    "plt.title('Quality Assurance Results')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Hypothesis Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Hypothesis test for mean Time of Effect\n",
    "t_stat, p_value = stats.ttest_1samp(data['time_of_effect'], popmean=specified_standard_time)\n",
    "print(f'T-statistic: {t_stat}, P-value: {p_value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = data[['time_of_effect']]\n",
    "y = data['quality_assurance']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion\n",
    "\n",
    "By following these steps, Sun Pharma can comprehensively test the new batch of painkiller drugs, ensuring they meet the required standards for both Time of Effect and Quality Assurance. The analysis will help in identifying any issues early and ensure that only the best products reach the market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "The quality assurance checks on the previous batches of drugs found that — it is 4 times more likely\n",
    "that a drug is able to produce a satisfactory result than not.\n",
    "Given a small sample of 10 drugs, you are required to find the theoretical probability that at most, 3\n",
    "drugs are not able to do a satisfactory job.\n",
    "a.) Propose the type of probability distribution that would accurately portray the above scenario,\n",
    "and list out the three conditions that this distribution follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "#### 1. Type of Probability Distribution\n",
    "\n",
    "The scenario described can be accurately portrayed by a **Binomial Distribution**. \n",
    "\n",
    "The Binomial Distribution is used to model the number of successes in a fixed number of independent Bernoulli trials (i.e., trials with two possible outcomes, such as success and failure).\n",
    "\n",
    "#### 2. Conditions of the Binomial Distribution\n",
    "\n",
    "The Binomial Distribution follows these three conditions:\n",
    "\n",
    "1. **Fixed Number of Trials (n)**:\n",
    "   - The experiment consists of a fixed number of trials. In this case, there are 10 drugs being tested.\n",
    "   \n",
    "2. **Independent Trials**:\n",
    "   - Each trial is independent of the others. The outcome of one drug's effectiveness does not affect the outcome of another.\n",
    "   \n",
    "3. **Constant Probability of Success (p)**:\n",
    "   - The probability of success (producing a satisfactory result) is constant for each trial. According to the problem, it is 4 times more likely for a drug to produce a satisfactory result than not.\n",
    "\n",
    "#### Probability Calculation\n",
    "\n",
    "To find the theoretical probability that at most 3 drugs are not able to do a satisfactory job, we can use the Binomial Distribution formula:\n",
    "\n",
    "\\[ P(X \\leq k) = \\sum_{i=0}^{k} \\binom{n}{i} p^i (1-p)^{n-i} \\]\n",
    "\n",
    "Where:\n",
    "- \\( n \\) is the number of trials (10 in this case).\n",
    "- \\( p \\) is the probability of failure (not satisfactory).\n",
    "- \\( 1-p \\) is the probability of success (satisfactory).\n",
    "- \\( X \\) is the random variable representing the number of failures.\n",
    "\n",
    "Given that it is 4 times more likely for a drug to be satisfactory than not, let \\( q \\) be the probability of failure (not satisfactory). Then, the probability of success (satisfactory) \\( p \\) can be expressed as:\n",
    "\n",
    "\\[ p = 4q \\]\n",
    "\n",
    "Since \\( p + q = 1 \\):\n",
    "\n",
    "\\[ 4q + q = 1 \\]\n",
    "\\[ 5q = 1 \\]\n",
    "\\[ q = \\frac{1}{5} = 0.2 \\]\n",
    "\\[ p = 1 - q = 0.8 \\]\n",
    "\n",
    "So, the probability of failure \\( q \\) (not satisfactory) is 0.2, and the probability of success \\( p \\) (satisfactory) is 0.8.\n",
    "\n",
    "Now we can calculate the probability that at most 3 drugs are not satisfactory:\n",
    "\n",
    "\\[ P(X \\leq 3) = \\sum_{i=0}^{3} \\binom{10}{i} (0.2)^i (0.8)^{10-i} \\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8791261183999999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# Number of trials\n",
    "n = 10\n",
    "\n",
    "# Probability of failure\n",
    "q = 0.2\n",
    "\n",
    "# Probability of success\n",
    "p = 0.8\n",
    "\n",
    "# Calculate cumulative probability of at most 3 failures\n",
    "prob_at_most_3_failures = binom.cdf(3, n, q)\n",
    "\n",
    "prob_at_most_3_failures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Executing the above code gives us the required probability.\n",
    "\n",
    "In summary, the appropriate probability distribution is the **Binomial Distribution**, and the conditions it follows are:\n",
    "1. Fixed number of trials.\n",
    "2. Independent trials.\n",
    "3. Constant probability of success.\n",
    "\n",
    "By calculating the cumulative probability \\( P(X \\leq 3) \\), we can determine the theoretical probability that at most 3 drugs are not able to produce a satisfactory result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "For the effectiveness test, a sample of 100 drugs was taken. The mean time of effect was 207\n",
    "seconds, with the standard deviation coming to 65 seconds. Using this information, you are required\n",
    "to estimate the range in which the population mean might lie — with a 95% confidence level.\n",
    "a.) Discuss the main methodology using which you will approach this problem. State all the\n",
    "properties of the required method. Limit your answer to 150 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "#### Methodology: Confidence Interval for Population Mean\n",
    "\n",
    "To estimate the range in which the population mean might lie with a 95% confidence level, we will use the concept of **Confidence Interval** (CI) for the mean.\n",
    "\n",
    "#### Properties of the Confidence Interval Method:\n",
    "\n",
    "1. **Sample Mean (\\(\\bar{x}\\))**:\n",
    "   - The average time of effect in the sample, which is 207 seconds.\n",
    "   \n",
    "2. **Sample Standard Deviation (s)**:\n",
    "   - The standard deviation of the sample, which is 65 seconds.\n",
    "\n",
    "3. **Sample Size (n)**:\n",
    "   - The number of observations in the sample, which is 100 drugs.\n",
    "\n",
    "4. **Confidence Level**:\n",
    "   - The desired confidence level is 95%.\n",
    "\n",
    "5. **Standard Error of the Mean (SEM)**:\n",
    "   - SEM is calculated as \\( \\frac{s}{\\sqrt{n}} \\).\n",
    "   - In this case, SEM = \\( \\frac{65}{\\sqrt{100}} = \\frac{65}{10} = 6.5 \\).\n",
    "\n",
    "6. **Critical Value (Z\\(_{\\alpha/2}\\))**:\n",
    "   - For a 95% confidence level, the critical value from the standard normal distribution (Z-distribution) is approximately 1.96.\n",
    "\n",
    "#### Confidence Interval Calculation:\n",
    "The 95% confidence interval for the population mean is given by:\n",
    "\n",
    "\\[ \\bar{x} \\pm Z_{\\alpha/2} \\times \\text{SEM} \\]\n",
    "\n",
    "Substituting the values:\n",
    "\n",
    "\\[ 207 \\pm 1.96 \\times 6.5 \\]\n",
    "\n",
    "#### Computation:\n",
    "\n",
    "\\[ 207 \\pm 12.74 \\]\n",
    "\n",
    "So, the 95% confidence interval for the population mean is:\n",
    "\n",
    "\\[ (194.26, 219.74) \\]\n",
    "\n",
    "This means that we are 95% confident that the true population mean time of effect lies between 194.26 seconds and 219.74 seconds.\n",
    "\n",
    "In summary, the method involves calculating the standard error of the mean, determining the critical value for the desired confidence level, and then using these to compute the confidence interval for the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below will compute and print the 95% confidence interval for the population mean based on the provided sample statistics.\n",
    "\n",
    "\n",
    "1. **Imports `scipy.stats`**:\n",
    "   - This library is used for statistical calculations, such as finding the critical value.\n",
    "\n",
    "2. **Define the Given Data**:\n",
    "   - Sample mean, sample standard deviation, sample size, and confidence level are defined based on the problem statement.\n",
    "\n",
    "3. **Calculate the Standard Error of the Mean (SEM)**:\n",
    "   - SEM is computed using the formula \\( \\text{SEM} = \\frac{\\text{sample\\_std\\_dev}}{\\sqrt{\\text{sample\\_size}}} \\).\n",
    "\n",
    "4. **Calculate the Critical Value (Z\\(_{\\alpha/2}\\))**:\n",
    "   - The critical value for a 95% confidence level is found using `stats.norm.ppf`, which gives the z-score corresponding to the upper tail of the normal distribution.\n",
    "\n",
    "5. **Calculate the Margin of Error**:\n",
    "   - The margin of error is calculated as the product of the critical value and the SEM.\n",
    "\n",
    "6. **Calculate the Confidence Interval**:\n",
    "   - The lower and upper bounds of the confidence interval are computed by subtracting and adding the margin of error from/to the sample mean.\n",
    "\n",
    "7. **Print the Confidence Interval**:\n",
    "   - The code prints the confidence interval for the population mean.\n",
    "\n",
    "This code will give you the range in which the population mean might lie with 95% confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% confidence interval for the population mean is (194.26, 219.74)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Given data\n",
    "sample_mean = 207\n",
    "sample_std_dev = 65\n",
    "sample_size = 100\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the standard error of the mean (SEM)\n",
    "sem = sample_std_dev / (sample_size ** 0.5)\n",
    "\n",
    "#The critical value for a 95% confidence level is found using stats.norm.ppf, which gives the z-score corresponding to the upper tail of the normal distribution.\n",
    "# Calculate the critical value (Z_alpha/2) for the 95% confidence level\n",
    "z_alpha_half = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = z_alpha_half * sem\n",
    "\n",
    "# Calculate the confidence interval\n",
    "lower_bound = sample_mean - margin_of_error\n",
    "upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "# Print the confidence interval\n",
    "print(f\"The 95% confidence interval for the population mean is ({lower_bound:.2f}, {upper_bound:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the claim that the newer batch of painkiller drugs has a time of effect of at most 200 seconds using two hypothesis testing methods, we can use:\n",
    "\n",
    "1. **Z-test** for the population mean (since the sample size is large, \\( n = 100 \\))\n",
    "2. **T-test** for the population mean (although the sample size is large, for completeness, we will also perform the T-test)\n",
    "\n",
    "We'll start by defining the hypotheses and then proceed with the calculations for both tests.\n",
    "\n",
    "### Hypotheses\n",
    "- **Null Hypothesis (\\(H_0\\))**: The mean time of effect is at most 200 seconds (\\(\\mu \\leq 200\\)).\n",
    "- **Alternative Hypothesis (\\(H_1\\))**: The mean time of effect is greater than 200 seconds (\\(\\mu > 200\\)).\n",
    "\n",
    "Since we are dealing with a \"greater than\" test, this is a one-tailed test.\n",
    "\n",
    "### Given Data\n",
    "- Sample mean (\\(\\bar{x}\\)) = 207 seconds\n",
    "- Sample standard deviation (\\(s\\)) = 65 seconds\n",
    "- Sample size (\\(n\\)) = 100\n",
    "- Significance level (\\(\\alpha\\)) = 0.05\n",
    "\n",
    "### Z-test\n",
    "\n",
    "1. **Calculate the Standard Error of the Mean (SEM)**:\n",
    "\\[ \\text{SEM} = \\frac{s}{\\sqrt{n}} = \\frac{65}{\\sqrt{100}} = \\frac{65}{10} = 6.5 \\]\n",
    "\n",
    "2. **Calculate the Z-score**:\n",
    "\\[ Z = \\frac{\\bar{x} - \\mu_0}{\\text{SEM}} = \\frac{207 - 200}{6.5} = \\frac{7}{6.5} \\approx 1.077 \\]\n",
    "\n",
    "3. **Find the critical Z-value for a 5% significance level (one-tailed)**:\n",
    "\\[ Z_{critical} = 1.645 \\]\n",
    "\n",
    "4. **Decision rule**:\n",
    "   - If \\( Z > Z_{critical} \\), reject the null hypothesis.\n",
    "   - If \\( Z \\leq Z_{critical} \\), fail to reject the null hypothesis.\n",
    "\n",
    "5. **Compare the test statistic with the critical value**:\n",
    "\\[ 1.077 \\leq 1.645 \\]\n",
    "\n",
    "Therefore, we fail to reject the null hypothesis using the Z-test.\n",
    "\n",
    "### T-test\n",
    "\n",
    "1. **Calculate the Standard Error of the Mean (SEM)** (same as Z-test):\n",
    "\\[ \\text{SEM} = 6.5 \\]\n",
    "\n",
    "2. **Calculate the T-score**:\n",
    "\\[ T = \\frac{\\bar{x} - \\mu_0}{\\text{SEM}} = \\frac{207 - 200}{6.5} = 1.077 \\]\n",
    "\n",
    "3. **Degrees of freedom (df)**:\n",
    "\\[ \\text{df} = n - 1 = 100 - 1 = 99 \\]\n",
    "\n",
    "4. **Find the critical T-value for a 5% significance level (one-tailed)** using a T-distribution table or a statistical software:\n",
    "\\[ T_{critical} \\approx 1.660 \\]\n",
    "\n",
    "5. **Decision rule**:\n",
    "   - If \\( T > T_{critical} \\), reject the null hypothesis.\n",
    "   - If \\( T \\leq T_{critical} \\), fail to reject the null hypothesis.\n",
    "\n",
    "6. **Compare the test statistic with the critical value**:\n",
    "\\[ 1.077 \\leq 1.660 \\]\n",
    "\n",
    "Therefore, we fail to reject the null hypothesis using the T-test.\n",
    "\n",
    "### Final Decision\n",
    "Based on both the Z-test and the T-test, we fail to reject the null hypothesis at the 5% significance level. This means that there is not enough evidence to support the claim that the mean time of effect for the newer batch of painkiller drugs is greater than 200 seconds. Therefore, we conclude that the newer batch of drugs passes the quality assurance test for having a mean time of effect of at most 200 seconds.\n",
    "\n",
    "### Python Code for Both Tests\n",
    "\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_mean = 207\n",
    "sample_std_dev = 65\n",
    "sample_size = 100\n",
    "population_mean = 200\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the Standard Error of the Mean (SEM)\n",
    "sem = sample_std_dev / np.sqrt(sample_size)\n",
    "\n",
    "# Z-test\n",
    "z_score = (sample_mean - population_mean) / sem\n",
    "z_critical = stats.norm.ppf(1 - alpha)\n",
    "\n",
    "# T-test\n",
    "t_score = (sample_mean - population_mean) / sem\n",
    "df = sample_size - 1\n",
    "t_critical = stats.t.ppf(1 - alpha, df)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Z-test: Z-score = {z_score:.3f}, Z-critical = {z_critical:.3f}\")\n",
    "if z_score > z_critical:\n",
    "    print(\"Reject the null hypothesis using Z-test.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis using Z-test.\")\n",
    "\n",
    "print(f\"T-test: T-score = {t_score:.3f}, T-critical = {t_critical:.3f}\")\n",
    "if t_score > t_critical:\n",
    "    print(\"Reject the null hypothesis using T-test.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis using T-test.\")\n",
    "```\n",
    "\n",
    "Running this code will provide the Z-score, T-score, and their respective critical values, allowing you to determine whether to reject or fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-test: Z-score = 1.077, Z-critical = 1.645\n",
      "Fail to reject the null hypothesis using Z-test.\n",
      "T-test: T-score = 1.077, T-critical = 1.660\n",
      "Fail to reject the null hypothesis using T-test.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_mean = 207\n",
    "sample_std_dev = 65\n",
    "sample_size = 100\n",
    "population_mean = 200\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the Standard Error of the Mean (SEM)\n",
    "sem = sample_std_dev / np.sqrt(sample_size)\n",
    "\n",
    "# Z-test\n",
    "z_score = (sample_mean - population_mean) / sem\n",
    "z_critical = stats.norm.ppf(1 - alpha)\n",
    "\n",
    "# T-test\n",
    "t_score = (sample_mean - population_mean) / sem\n",
    "df = sample_size - 1\n",
    "t_critical = stats.t.ppf(1 - alpha, df)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Z-test: Z-score = {z_score:.3f}, Z-critical = {z_critical:.3f}\")\n",
    "if z_score > z_critical:\n",
    "    print(\"Reject the null hypothesis using Z-test.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis using Z-test.\")\n",
    "\n",
    "print(f\"T-test: T-score = {t_score:.3f}, T-critical = {t_critical:.3f}\")\n",
    "if t_score > t_critical:\n",
    "    print(\"Reject the null hypothesis using T-test.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis using T-test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "Now, once the batch has passed all the quality tests and is ready to be launched in the market, the marketing team needs to plan an effective online ad campaign to attract new customers. Two taglines were proposed for the campaign, and the team is currently divided on which option to use.\n",
    "Explain why and how A/B testing can be used to decide which option is more effective. Give a stepwise procedure for the test that needs to be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B Testing for Tagline Effectiveness\n",
    "\n",
    "**A/B testing** (or split testing) is a method used to compare two versions of a webpage, ad, or any other marketing material to determine which one performs better. In this case, we will use A/B testing to compare the effectiveness of two taglines for an online ad campaign.\n",
    "\n",
    "### Why Use A/B Testing?\n",
    "\n",
    "- **Data-Driven Decision Making:** It allows decisions to be made based on data rather than assumptions or opinions.\n",
    "- **Objective Comparison:** Provides a scientific way to compare the performance of two different taglines.\n",
    "- **User-Centric:** Measures actual user behavior and reactions to the taglines.\n",
    "\n",
    "### Step-by-Step Procedure for Conducting A/B Testing\n",
    "\n",
    "#### Step 1: Define the Goal\n",
    "The primary goal is to determine which tagline leads to more conversions (e.g., click-throughs, sign-ups, or purchases).\n",
    "\n",
    "#### Step 2: Formulate Hypotheses\n",
    "- **Null Hypothesis (\\(H_0\\))**: There is no difference in effectiveness between Tagline A and Tagline B.\n",
    "- **Alternative Hypothesis (\\(H_1\\))**: There is a difference in effectiveness between Tagline A and Tagline B.\n",
    "\n",
    "#### Step 3: Identify Key Metrics\n",
    "Decide on the metrics to measure the effectiveness. Common metrics include:\n",
    "- Click-through rate (CTR)\n",
    "- Conversion rate\n",
    "- Engagement rate\n",
    "\n",
    "#### Step 4: Select the Sample Size\n",
    "Determine the sample size needed to achieve statistical significance. Tools like online sample size calculators can be used to calculate the required number of users.\n",
    "\n",
    "#### Step 5: Randomly Assign Users\n",
    "Randomly divide the users into two groups:\n",
    "- **Group A**: Sees Tagline A\n",
    "- **Group B**: Sees Tagline B\n",
    "\n",
    "#### Step 6: Run the Test\n",
    "- **Duration**: Ensure the test runs for a sufficient period to collect enough data (e.g., a few days to a couple of weeks).\n",
    "- **Consistent Conditions**: Ensure both groups experience the same conditions except for the tagline.\n",
    "\n",
    "#### Step 7: Collect Data\n",
    "Monitor and record the performance of both taglines based on the defined metrics.\n",
    "\n",
    "#### Step 8: Analyze Results\n",
    "Use statistical analysis to compare the performance of the two taglines. A common approach is to use a chi-square test for proportions if comparing conversion rates.\n",
    "\n",
    "#### Step 9: Make a Decision\n",
    "Based on the statistical analysis:\n",
    "- **If the null hypothesis is rejected**: Choose the tagline with the higher conversion rate.\n",
    "- **If the null hypothesis is not rejected**: Either tagline can be used as there is no significant difference in performance.\n",
    "\n",
    "#### Step 10: Implement the Winning Tagline\n",
    "Deploy the more effective tagline across the entire campaign to maximize conversions.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "A/B testing is a robust method for making data-driven decisions about which tagline to use in the online ad campaign. By following the outlined steps, the marketing team can ensure that they choose the tagline that is most likely to attract new customers and achieve the desired business outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 1.166\n",
      "P-value: 0.122\n",
      "Fail to reject the null hypothesis: No significant difference between Tagline A and Tagline B.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Example data\n",
    "conversions_A = 150\n",
    "visitors_A = 2000\n",
    "conversions_B = 170\n",
    "visitors_B = 2000\n",
    "\n",
    "# Conversion rates\n",
    "conversion_rate_A = conversions_A / visitors_A\n",
    "conversion_rate_B = conversions_B / visitors_B\n",
    "\n",
    "# Pooled conversion rate\n",
    "pooled_conversion_rate = (conversions_A + conversions_B) / (visitors_A + visitors_B)\n",
    "\n",
    "# Standard error\n",
    "std_error = ((pooled_conversion_rate * (1 - pooled_conversion_rate)) * (1 / visitors_A + 1 / visitors_B)) ** 0.5\n",
    "\n",
    "# Z-score\n",
    "z_score = (conversion_rate_B - conversion_rate_A) / std_error\n",
    "\n",
    "# P-value\n",
    "p_value = 1 - stats.norm.cdf(z_score)\n",
    "\n",
    "print(f\"Z-score: {z_score:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between Tagline A and Tagline B.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference between Tagline A and Tagline B.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
